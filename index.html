<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight: 300;
        font-size: 17px;
        margin-left: auto;
        margin-right: auto;
        width: 980px;
    }

    h1 {
        font-weight: 300;
        line-height: 1.15em;
    }

    h2 {
        font-size: 1.75em;
    }

    a:link, a:visited {
        color: #B6486F;
        text-decoration: none;
    }

    a:hover {
        color: #208799;
    }

    h1, h2, h3 {
        text-align: center;
    }

    h1 {
        font-size: 40px;
        font-weight: 500;
    }

    h2 {
        font-weight: 400;
        margin: 16px 0px 4px 0px;
    }

    .paper-title {
        padding: 16px 0px 16px 0px;
    }

    section {
        margin: 32px 0px 32px 0px;
        text-align: justify;
        clear: both;
    }

    .col-5 {
        width: 20%;
        float: left;
    }

    .col-4 {
        width: 25%;
        float: left;
    }

    .col-3 {
        width: 33%;
        float: left;
    }

    .col-2 {
        width: 50%;
        float: left;
    }

    .col-1 {
        width: 100%;
        float: left;
    }

    .row, .author-row, .affil-row {
        overflow: auto;
    }

    .author-row, .affil-row {
        font-size: 26px;
    }

    .row {
        margin: 16px 0px 16px 0px;
    }

    .authors {
        font-size: 26px;
    }

    .affil-row {
        margin-top: 16px;
    }

    .teaser {
        max-width: 100%;
    }

    .text-center {
        text-align: center;
    }

    .screenshot {
        width: 256px;
        border: 1px solid #ddd;
    }

    .screenshot-el {
        margin-bottom: 16px;
    }

    hr {
        height: 1px;
        border: 0;
        border-top: 1px solid #ddd;
        margin: 0;
    }

    .material-icons {
        vertical-align: -6px;
    }

    p {
        line-height: 1.25em;
    }

    .caption {
        font-size: 16px;
        /*font-style: italic;*/
        color: #666;
        text-align: center;
        margin-top: 4px;
        margin-bottom: 10px;
    }

    video {
        display: block;
        margin: auto;
    }

    figure {
        display: block;
        margin: auto;
        margin-top: 10px;
        margin-bottom: 10px;
    }

    #bibtex pre {
        font-size: 13.5px;
        background-color: #eee;
        padding: 16px;
    }

    .blue {
        color: #2c82c9;
        font-weight: bold;
    }

    .orange {
        color: #d35400;
        font-weight: bold;
    }

    .flex-row {
        display: flex;
        flex-flow: row wrap;
        justify-content: space-around;
        padding: 0;
        margin: 0;
        list-style: none;
    }

    .paper-btn {
        position: relative;
        text-align: center;

        display: inline-block;
        margin: 8px;
        padding: 8px 8px;

        border-width: 0;
        outline: none;
        border-radius: 2px;

        background-color: #B6486F;
        color: white !important;
        font-size: 20px;
        width: 100px;
        font-weight: 600;
    }

    .paper-btn-parent {
        display: flex;
        justify-content: center;
        margin: 16px 0px;
    }

    .paper-btn:hover {
        opacity: 0.85;
    }

    .container {
        margin-left: auto;
        margin-right: auto;
        padding-left: 16px;
        padding-right: 16px;
    }

    .venue {
        /*color: #B6486F;*/
        font-size: 30px;

    }

</style>

<!-- End : Google Analytics Code-->
<script type="text/javascript" src="../js/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
      rel='stylesheet' type='text/css'>
      <head>
        <title>DensePure: Understanding Diffusion Models towards Adversarial Robustness</title>
        <meta property="og:description" content="DensePure: Understanding Diffusion Models towards Adversarial Robustness"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="">
        <meta name="twitter:title" content="DensePure: Understanding Diffusion Models towards Adversarial Robustness">
        <meta name="twitter:description"
              content="We propose <i>DensePure</i>.">
        <meta name="twitter:image" content="">
    </head>

<body>
<div class="container">
    <div class="paper-title">
        <h1>DensePure: Understanding Diffusion Models towards Adversarial Robustness</h1>
    </div>

    <div id="authors">
        <center>
            <div class="author-row">
                <div class="col-3 text-center"><a href="https://xiaocw11.github.io/">Chaowei Xiao</a><sup>1,3</sup></div>
                <div class="col-3 text-center"><a href="https://sites.google.com/umich.edu/zhongzhc/home?pli=1">Zhongzhu Chen</a><sup>2</sup>
                </div>
                <div class="col-3 text-center"><a href="https://scholar.google.com/citations?user=T8i4IpgAAAAJ&hl=en">Kun Jin</a><sup>2</sup>
                </div>
                <div class="col-3 text-center"><a href="https://jayfeather1024.github.io/jxwang.github.io/">Jiongxiao Wang</a><sup>1</sup>
                </div>
                <div class="col-3 text-center"><a href="https://weilinie.github.io/">Weili Nie</a><sup>3</sup></div>
                <div class="col-3 text-center"><a href="https://liu.engin.umich.edu/">Mingyan Liu</a><sup>2</sup></div>
                <div class="col-3 text-center"><a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima
                    Anandkumar</a><sup>3,4</sup></div>
                <div class="col-3 text-center"><a href="https://aisecure.github.io/">Bo Li</a><sup>5</sup></div>
                <div class="col-3 text-center"><a href="http://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a><sup>6</sup></div>
                
            </div>


            <center>
                <table style="height: 200px;" width="500px" align="center">
                    <tbody>
                        <tr>
                            <td style="width: 200px;" align="center"><span style="font-size: 20px;"><sup>1</sup> Arizona State University</span></td>
                            <td style="width: 200px;" align="center"><span style="font-size: 20px;"><sup>2</sup> University of Michigan, Ann Arbor</span></td>
                            <td style="width: 200px;" align="center"><span style="font-size: 20px;"><sup>3</sup> NVIDIA</span></td>
                        </tr>
                        <tr>
                            <td style="width: 200px;" align="center"><span style="font-size: 20px;"><sup>4</sup> Caltech</span></td>
                            <td style="width: 200px;" align="center"><span style="font-size: 20px;"><sup>5</sup> UIUC</span></td>
                            <td style="width: 200px;" align="center"><span style="font-size: 20px;"><sup>6</sup> UC Berkeley</span></td>
                        </tr>
                    </tbody>
                </table>
            </center>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="paper-btn" href="https://arxiv.org/pdf/2211.00322.pdf">
                    <span class="material-icons"> description </span>
                    Paper
                </a>
                <a class="paper-btn" href="https://github.com/Jayfeather1024/DensePure.git">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
        </div>
    </div>

    <section id="abstract"/>
    <h2>Abstract</h2>
    <hr>
    <div class="flex-row">
        <p>
            Diffusion models have been recently employed to improve certified robustness through the process of denoising. 
            However, the theoretical understanding of why diffusion models are able to improve the certified robustness is 
            still lacking, preventing from further improvement. In this study, we close this gap by analyzing the fundamental 
            properties of diffusion models and establishing the conditions under which they can enhance certified robustness. 
            This deeper understanding allows us to propose a new method DensePure, designed to improve the certified robustness 
            of a pretrained model (i.e. classifier). Given an (adversarial) input, DensePure consists of multiple runs of denoising 
            via the reverse process of the diffusion model (with different random seeds) to get multiple reversed samples, which 
            are then passed through the classifier, followed by majority voting of inferred labels to make the final prediction. 
            This design of using multiple runs of denoising is informed by our theoretical analysis of the conditional distribution 
            of the reversed sample. Specifically, when the data density of a clean sample is high, its conditional density under 
            the reverse process in a diffusion model is also high; thus sampling from the latter conditional distribution can purify 
            the adversarial example and return the corresponding clean sample with a high probability. By using the highest density 
            point in the conditional distribution as the reversed sample, we identify the robust region of a given instance under 
            the diffusion model's reverse process. We show that this robust region is a union of multiple convex sets, and is 
            potentially much larger than the robust regions identified in previous works. In practice, DensePure can approximate the 
            label of the high density region in the conditional distribution so that it can enhance certified robustness. We conduct 
            extensive experiments to demonstrate the effectiveness of DensePure by evaluating its certified robustness given a 
            standard model via randomized smoothing. We show that DensePure is consistently better than existing methods on ImageNet, 
            with 7% improvement on average.
        </p>
    </div>
    </section>

    <section id="theroetical analysis"/>
    <h2>Theroetical Contributions</h2>
    <hr>
    <div class="flex-row">
        <p>In this paper, we provide theroetical analysis about the ability of diffusion models to improve certified robustness. Our main
            contributions are as the following: (i) explain why and how the diffusion model purifies adversarial attacks to improve 
            the adversarial robustness; (ii) derive the robust region and robust radius of diffusion models, which has the potential to provide a large 
            robust region.
        </p>
    </div>
    <figure style="width: 100%">
        <center><img width="65%" src="assets/D_sub_figure.png"></center>
        <p class="caption" style="margin-bottom: 24px;">
            An illustration of the robust region, where x<sub>0</sub>, x<sub>1</sub>, x<sub>2</sub> are samples with ground-trueth label 
            and x<sub>3</sub> is a sample with another label. x<sub>a</sub> = x<sub>0</sub> + ε<sub>a</sub> is an adversarial sample with 
            correct classification but it could not be reversed back to x<sub>0</sub>. The blue and green shades are recovery regions where noise
            samples can be reversed back to their original ones by diffusion models. When we have a data region with higher data density 
            and larger distances to data regions with other labels like blue shade in the picture, we can gain a larger robust radius like 
            r(x<sub>0</sub>) other than the radius r<sub>sub</sub>(x<sub>0</sub>) which is restricted in the recovery region of x<sub>0</sub>.
        </p>
    </figure>
    </section>


    <section id="framework"/>
    <h2>DensePure Framework</h2>
    <hr>
    <div class="flex-row">
        <p>
            Theroetical analysis on diffusion models allows us to propose a new method DensePure to improve the certified 
            robustness of any given classifier by more effectively using the diffusion model.
            DensePure incorporates two steps: (i) using the reverse process of the diffusion model to obtain a sample of the
            posterior data distribution conditioned on the adversarial input; and (ii) repeating the reverse process
            multiple times with different random seeds to approximate the label of high density region in the
            conditional distribution via a majority vote. In particular, given an adversarial input, we repeatedly
            feed it into the reverse process of the diffusion model to get multiple reversed examples and feed
            them into the classifier to get their labels. We then apply the majority vote on the set of labels to get
            the final predicted label.
        </p>
    </div>
    <figure style="width: 100%">
        <center><img width="100%" src="assets/densepure_flowchart.png"></center>
        <p class="caption" style="margin-bottom: 24px;">
            Pipeline of DensePure
        </p>
    </figure>
    </section>


    <section id="results"/>
    <h2>Main Results</h2>
    <hr>
    <div class="flex-row">
        <p>
            We empirically compare our methods against other certified robustness baselines under randomized smoothing, especially Carlini et al. (2022), which is also 
            an off-the-shelf method with diffusion models. Extensive experiments and ablation study on CIFAR-10 and ImageNet demonstrate the state-of-the-art performance
            of DensePure.
        </p>
        <p>
            <b>- Compared with existing works.</b> Compared to both on-the-shelf and off-the-shelf existing randomized smoothing methods, our method shows large improvement on
            CIFAR-10 in most cases and consistently better than existing methods on ImageNet, with 7% improvement on average.
        </p>
        <figure style="width: 100%;">
            <a href="assets/table.png">
                <center><img width="100%" src="assets/table.png"></center>
            </a>
            <p class="caption" style="margin-bottom: 24px;">
                Certified accuracy compared with existing works. The certified accuracy at σ = 0 for each
                model is in the parentheses. The certified accuracy for each cell is from the respective papers except
                Carlini et al. (2022). Our diffusion model and classifier are the same as Carlini et al. (2022), where
                the off-the-shelf classifier uses ViT-based architectures trained on a large dataset (ImageNet-22k).
                Comparison with state-of-the-art adversarial training methods against AutoAttack on ImageNet with
                ResNet-50 and DeiT-S, respectively.
            </p>
        </figure>

        <p>
            <b>- Compared with Carlini et al. (2022).</b> To better understand the importance of DensePure design, that approximates 
            the label of the high density region in the conditionaldistribution, we compare DensePure in a more fine-grained manner 
            with Carlini et al. (2022), which also uses the diffusion model. Experiment results show that our method is consistently 
            better than Carlini et al. (2022) to reach higher certified robustness.
        </p>
        <figure style="width: 100%;">
            <a href="assets/main_results.jpg">
                <center><img width="100%" src="assets/main_results.jpg"></center>
            </a>
            <p class="caption" style="margin-bottom: 24px;">
                Comparing our method vs Carlini et al. (2022) on CIFAR-10 and ImageNet. The lines
                represent the certified accuracy with different L<sub>2</sub> perturbation bound with different Gaussian noise
                σ ∈ {0.25, 0.50, 1.00}.
            </p>
        </figure>
        
    </div>
    </section>

    <section id="limitations"/>
    <h2>Our Insights and Limitations</h2>
    <hr>
    <div class="flex-row">
        <p>
            In this work, we theoretically prove that the diffusion model could purify adversarial examples back
            to the corresponding clean sample with high probability, as long as the data density of the corresponding 
            clean samples is high enough. Our theoretical analysis characterizes the conditional
            distribution of the reversed samples given the adversarial input, generated by the diffusion model
            reverse process. Using the highest density point in the conditional distribution as the deterministic
            reversed sample, we identify the robust region of a given instance under the diffusion model reverse 
            process, which is potentially much larger than previous methods. Our analysis inspires us to
            propose an effective pipeline DensePure, for adversarial robustness. We conduct comprehensive
            experiments to show the effectiveness of DensePure by evaluating the certified robustness via the
            randomized smoothing algorithm. Note that DensePure is an off-the-shelf pipeline that does not
            require training a smooth classifier. Our results show that DensePure achieves the new SOTA certified 
            robustness for perturbation with L<sub>2</sub>-norm. We hope that our work sheds light on an in-depth
            understanding of the diffusion model for adversarial robustness.
        </p>
        <p>
            One main limitation of our method is the time complexity, because DensePure requires repeating the reverse
            process multiple times. In this paper, we use fast sampling to reduce the time complexity and show that
            with reduced sampling and majority votes numbers, we can still achieve nontrivial certified accuracy. We leave the more
            advanced fast sampling strategy as the future direction.
        </p>
    </div>
    </section>


    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href=""><img class="screenshot" src="assets/arxiv_preview.jpg"></a>
            </div>
            <div style="width: 50%; font-size: 20px;">
                <p><b>Diffusion Models for Adversarial Purification</b></p>
                <p>Chaowei Xiao, Zhongzhu Chen, Kun Jin, Jiongxiao Wang, Weili Nie, Mingyan Liu, 
                    Anima Anandkumar, Bo Li, Dawn Song</p>
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/pdf/2211.00322.pdf"> arXiv
                    version</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="https://scholar.googleusercontent.com/scholar.bib?q=info:nDcvPmoyt60J:scholar.google.com/&output=citation&scisdr=CgXjz32ZELfQxS5A1tA:AAGBfm0AAAAAY7JGztDSBBpEr07oruE0kSsLwp_Nv6xq&scisig=AAGBfm0AAAAAY7JGznDwl4LydBuZj-gATgB5YDEsk8_m&scisf=4&ct=citation&cd=-1&hl">
                    BibTeX</a>
                </div>
                <div><span class="material-icons"> integration_instructions </span><a
                        href="https://github.com/Jayfeather1024/DensePure.git"> Code</a></div>
            </div>
        </div>
    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@article{xiao2022densepure,
  title={DensePure: Understanding Diffusion Models towards Adversarial Robustness},
  author={Xiao, Chaowei and Chen, Zhongzhu and Jin, Kun and Wang, Jiongxiao and Nie, Weili and Liu, Mingyan and Anandkumar, Anima and Li, Bo and Song, Dawn},
  journal={arXiv preprint arXiv:2211.00322},
  year={2022}
}</code></pre>
    </section>
</div>
</body>
</html>
